Linear Regression is a supervised learning algorithm which is both a statistical and a machine learning algorithm. It is used to predict the real-valued output y based on the given input value x. 
It depicts the relationship between the dependent variable y and the independent variables xi  ( or features ).  
The hypothetical function used for prediction is represented by h( x )




Linear regression aims to establish a linear relationship between the input variables (features) and the output variable (target). 
The goal is to find the best-fitting line that minimizes the difference between predicted and actual values. Mathematically, this line can be represented as:

y = wx + b â€¦â€¦â€¦â€¦â€¦â€¦..(eq 1)

Simple Linear Regression:
Simple Linear Regression specifically refers to the case where there is only one independent variable (x) predicting a single dependent variable (y). 
The relationship between x and y is modeled as a straight line, represented by the equation:

y=mx+bâ€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦eq(2)


<img width="793" height="594" alt="Screenshot 2026-02-23 at 4 01 08â€¯PM" src="https://github.com/user-attachments/assets/f68144f8-a2dd-4cd6-a52d-32bc3ebd8543" />


The linear regression model aims to find the optimal values for w and b that minimize the difference between the predicted values and the actual observations. 
The weight (w) governs the influence of the input variable, determining the slope of the fitted line, while the bias (b) allows for an adjustment of the lineâ€™s position on the y-axis.
The interplay of these components forms the basis for constructing an effective linear regression model that accurately captures the underlying relationships within the data.



1ï¸âƒ£ The Core Idea

Linear regression answers this question:

â€œIf X changes, how does Y change?â€

Example:

Hours studied â†’ Exam score

House size â†’ House price

Years of experience â†’ Salary

We assume there is a linear relationship between input and output.

That means:

ğ‘Œâ‰ˆ ğ‘ğ‘‹ + b
Yâ‰ˆaX+b


